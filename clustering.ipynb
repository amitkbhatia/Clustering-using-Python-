{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to choose a good number of clusters for a dataset using the k-means inertia graph\n",
    "\n",
    "Inertia measures how spread out the clusters are (lower the better). In other words, it measures the distance from each sample to the centroid of its cluster. In the graph of inertia vs a number of clusters look at elbow points to find out the optimum number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "# Import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters=k)\n",
    "    # Fit model to sample_dataset\n",
    "    model.fit(sample_dataset)\n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data standardization and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Create scaler: scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler,kmeans)\n",
    "\n",
    "# Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(samples)\n",
    "\n",
    "# Create a DataFrame with labels and species as columns: df\n",
    "df = pd.DataFrame({'labels':labels, 'species':species})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'],df['species'])\n",
    "\n",
    "# Display ct\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering\n",
    "\n",
    "In Hierarchical clustering bottom-up approach, each variable begins in a separate cluster and at each step, the two closer cluster are merged. This process continues until all variables are in the single cluster. Hierarchical clustering is more intuitive and we are not required to give the number of clusters beforehand. The disadvantage of Hierarchical clustering is that it can handle only a few data-points and takes exponential time for the high number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to choose a good number of clusters for a dataset using the Hierarchical clustering\n",
    "\n",
    "The best choice of the number of clusters is the number of vertical lines in the dendrogram cut by a horizontal line that can transverse the maximum distance vertically without intersecting a cluster.\n",
    "In Python, SciPy linkage () function performs hierarchical clustering on an array of samples with the method='complete' or ‘single’. In the complete linkage, the distance between clusters is the distance between the furthest points of the clusters. In single linkage, the distance between clusters is the distance between the closest points of the clusters. We can use dendrogram () to visualize the result. It may be noted that height on dendrogram specifies the maximum distance between merging clusters. We can use the fcluster() function to extract the cluster labels for this intermediate clustering and compare the labels with the grain varieties using a cross-tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# SciPy hierarchical clustering doesn't fit into a sklearn pipeline, so we need to use the \n",
    "# normalize() function from sklearn.preprocessing instead of Normalizer.\n",
    "\n",
    "# Import normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "# Normalize the movements: normalized_movements\n",
    "normalized_movements = normalize(sample_data)\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(normalized_movements, method='complete')\n",
    "\n",
    "\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "dendrogram(mergings,labels=varieties, leaf_rotation=90,leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method of clustering is t-SNE. t-SNE maps the data samples into 2d space so that the proximity of the samples to one another can be visualized. “t-SNE stands for t-distributed stochastic neighbor embedding”\n",
    "t-SNE provides great visualizations when the individual samples can be labeled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "# Create a TSNE instance: model\n",
    "model = TSNE(learning_rate=200)\n",
    "\n",
    "# Apply fit_transform to samples: tsne_features\n",
    "tsne_features = model.fit_transform(sample_data)\n",
    "\n",
    "# Select the 0th feature: xs\n",
    "xs = tsne_features[:,0]\n",
    "\n",
    "# Select the 1st feature: ys\n",
    "ys = tsne_features[:,1]\n",
    "# Scatter plot, coloring by variety_numbers\n",
    "plt.scatter(xs,ys,c=variety_numbers)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
